{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os \n",
    "\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_file = os.path.join('..', 'data', 'protein-seqs-2018-01-16-131956.txt')\n",
    "functions_file = os.path.join('..', 'data', 'protein-functions-2018-01-16-131956.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(functions_file) as fn_file:\n",
    "    has_function = json.load(fn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_function  # just to see what we have loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_size = 500   # any sequence longer than this, we ignore (just for now) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []           # sequences in the same order corresponding to elements of p \n",
    "y = []           # output class: 1 if protein has the function, 0 if not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seeing how many examples we've found for each class \n",
    "pos_examples = 0\n",
    "neg_examples = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sequences_file) as f:\n",
    "    for line in f:\n",
    "        ln = line.split(',')\n",
    "        protein_id = ln[0].strip()\n",
    "        seq = ln[1].strip()\n",
    "\n",
    "        # we're doing this to reduce input size\n",
    "        if len(seq) >= max_sequence_size:\n",
    "            continue\n",
    "        \n",
    "        print(line)\n",
    "        \n",
    "        X.append(seq)\n",
    "        \n",
    "        if protein_id in has_function: \n",
    "            y.append(1) \n",
    "            pos_examples += 1 \n",
    "        else: \n",
    "            y.append(0) \n",
    "            neg_examples += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Positive Examples: %d\" % pos_examples)\n",
    "print(\"Negative Examples: %d\" % neg_examples)  # Total is different because we ignored longer sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_indices(sequence):\n",
    "    \"\"\"Convert amino acid letters to indices. \n",
    "       _ means no amino acid (used for padding to accommodate for variable length)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        acid_letters = ['_', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M',\n",
    "                'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "        indices = [acid_letters.index(c) for c in list(sequence)]\n",
    "        return indices\n",
    "    except Exception:\n",
    "        print(sequence)\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_indices('AD')  # just testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = [] \n",
    "for i in range(len(X)): \n",
    "    x = sequence_to_indices(X[i])\n",
    "    X_all.append(x) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0])\n",
    "print(X_all[0])\n",
    "print(len(X_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = sequence.pad_sequences(X_all, maxlen=max_sequence_size)  # to overcome the variable length issue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_all.shape)  # extremely important that you view this! \n",
    "print(y_all.shape)  # make sure you are comfortable with shapes! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a basic shuffle and 66%, 33% split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_all.shape[0]  # number of data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize to shuffle first\n",
    "randomize = np.arange(n)\n",
    "np.random.shuffle(randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all[randomize]\n",
    "y_all = y_all[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = round(n * 2 / 3)\n",
    "X_train = X_all[:test_split]   # start to (just before) test_split \n",
    "y_train = y_all[:test_split]   \n",
    "X_test  = X_all[test_split:]   # test_split to end \n",
    "y_test  = y_all[test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes again \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"     [  .  .  .  .  .  5 ]         Initial shape: (5, )   \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     [ [. . . . . . . . 500 ]    []   []   []   []  ]      \n",
    "\n",
    "Shape is now: (5, 500)\n",
    "\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This, when converted to one-hot representation becomes: \n",
    "\n",
    "\"\"\" \n",
    "[ [\n",
    "   [. . . . . . . . . . 23]             (where 23 is the number of amino acids)\n",
    "    . \n",
    "    .\n",
    "    .\n",
    "    500 \n",
    "  ]    \n",
    "  []   \n",
    "  []   \n",
    "  []   \n",
    "  []  \n",
    "  ] \n",
    "  \n",
    "  So, the final shape will be: (5, 500, 23)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_amino_acids = 23 \n",
    "embedding_dims = 10 \n",
    "nb_epoch = 2\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Embedding(num_amino_acids, embedding_dims, input_length=max_sequence_size  ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(25, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                  batch_size = batch_size,\n",
    "                  epochs = nb_epoch, \n",
    "                  validation_data = (X_test, y_test),\n",
    "                  verbose=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing to the Functional API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_sequence_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(num_amino_acids, embedding_dims)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(embedding)\n",
    "x = Dense(25, activation='sigmoid')(x)\n",
    "x = Dense(1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Activation('sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "                  batch_size = batch_size,\n",
    "                  epochs = nb_epoch, \n",
    "                  validation_data = (X_test, y_test),\n",
    "                  verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

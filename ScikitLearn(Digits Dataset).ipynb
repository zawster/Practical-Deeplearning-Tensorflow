{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognization of Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}\n"
     ]
    }
   ],
   "source": [
    "print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(digits.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target)\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 8 8 4 9 0 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(digits.target.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn to Predict the class(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying classifier with learning parameters\n",
    "clf = svm.SVC(gamma=0.001, C=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fiting or training model\n",
    "clf.fit(digits.data[:-2] , digits.target[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting\n",
    "clf.predict(digits.data[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f779258aba8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(2,2))\n",
    "plt.imshow(digits.images[-1], interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f779262ccf8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[-2], interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
